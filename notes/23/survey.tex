\section{Survey}
Here, we have a survey of results and open problems concerning LPN.

\begin{definition}[(Search) Learning Parity with Noise~\cite{Piet12}]
	For $\tau \in (0,1/2)$, $\ell \in \bbN$, the search $\pred{LPN}_{\tau, \ell}$ problem is $(n, t, \epsilon)$-hard if for every distinguisher $\pred{D}$ running in time $t$,
	\begin{align*}
		\underset{\vec{s}, \vec{A}, \vec{e}}{\pr}\left[\pred{D}\left(\vec{A}, \vec{As}\xor\vec{e}\right)=\vec{s}\right] \leq \epsilon,
	\end{align*}
	where $\vec{s} \getsr \bbZ^\ell_2$, $\vec{A} \getsr \bbZ^{n\times \ell}_2$, and $\vec{e} \drawn \pred{Ber}^n_\tau$.
\end{definition}
Next we have the seemingly stronger version of LPN, namely Decisional LPN.
\begin{definition}[(Decisional) Learning Parity with Noise~\cite{Piet12}]
	For $\tau \in (0,1/2)$, $\ell \in \bbN$, the search $\pred{LPN}_{\tau, \ell}$ problem is $(n, t, \epsilon)$-hard if for every distinguisher $\pred{D}$ running in time $t$,
	\begin{align*}
	\abs{\underset{\vec{s}, \vec{A}, \vec{e}}{\pr}\left[\pred{D}\left(\vec{A}, \vec{As}\xor\vec{e}\right) = 1\right] -
	\underset{\vec{r}, \vec{A}}{\pr}\left[\pred{D}\left(\vec{A}, \vec{r} \right)=1\right] } \leq \epsilon,
	\end{align*}
	where $\vec{s} \getsr \bbZ^\ell_2$, $\vec{A} \getsr \bbZ^{n\times \ell}_2$, $\vec{e} \drawn \pred{Ber}^n_\tau$, and $\vec{r}\getsr\bbZ^n_2$.
\end{definition}



\noindent Here is a summary for LPN. 
\begin{enumerate}
	\item Decisional and search problems are polynomially equivalent \cite{C:BFKL93,JC:KatShiSmi10}.
	The following lemma gives the result formally.
	
	\begin{importedlemma}[{\cite[Lemma 1]{JC:KatShiSmi10}}]
		If decisional $\LPN_{\tau, \ell}$ is not $(q,t,\eps)$ secure, then search $\LPN_{\tau,\ell}$ is not $O(q',t',\eps')$ secure, where
		\begin{align*}
			q' = O(q\cdot \log \ell/\eps^2) & & t' = O(t\cdot \ell \cdot \log \ell/\eps^2) & & \eps' = \eps/4.
		\end{align*}
	\end{importedlemma}
	
	\item The search LPN problem can be stated as the NP-complete problem of decoding random linear code \cite{BerlMcElTilb78}.
	\item The best known algorithms to recover an $ \ell $ bit secret need $ 2^{\Theta(\ell / \log \ell)} $ time and samples \cite{STOC:BluKalWas00,Levieil06}. 
	If given only polynomially many $ q = \pred{poly}(\ell) $ samples, the running time of best known algorithms becomes to $ 2^{\Theta(\ell/ \log \log \ell)} $ \cite{Lyubashevsky05}.
	Further, when given only linearly many samples $ q = \Theta(\ell) $, the best known algorithms have running time $ 2^{\Theta(\ell)} $ \cite{AC:MayMeuTho11,Jacques89}. 
	Unlike most others, no quantum algorithms for LPN are known which are significantly faster than the classical ones. 
	
	\item The secret $ s $ is usually assumed to be uniformly random. 
	This is one of the hardest distributions.  
	The LPN problem where $ \vec{s} \getsr \pred{Ber}^n_\tau $ is as hard as for uniform $ \vec{s} \getsr  \bbZ^n_2 $ \cite{C:ACPS09}. 
	\textcolor{red}{Nothing is known about the hardness of LPN for \textit{general} distributions of high min-entropy.} 
	However, subspace LPN problem \cite{Piet12} is equivalent to (as hard as) the LPN problem. 
	In this case, the secret $s \in \bbZ^\ell_2$ is uniformly sampled from $V \subseteq \bbZ^\ell_2$ such that $\dim(V) = \ell' \leq \ell$ (\ie, any $s \getsr V$ has min-entropy $\ell'$).
	This can be shown to be exactly as hard as the standard LPN problem with an $\ell'$-bit uniform secret.
	
	\item Sampling of the random matrix $ A  \getsr \bbZ^{n\times \ell}_2 $ is the most expensive part in generating LPN. 
	Using Toeplitz matrix requires only $ n + \ell $ random bits (as opposed $ n \cdot \ell $) \cite{EC:GilRobSeu08}. 
	\textcolor{red}{Can we use  Wozencraft's technique to save randomness?} 
	One major drawback of this is that it requires $ n = 2 \ell $.
	\textcolor{red}{What if $A$ is drawn from a high min-entropy source? (Beyond linear subspace, which can be proven to be hard still.)}
	
	\item  \textbf{Exact LPN (XLPN).} A minor variation of LPN where $ \vec{e} $ has weight exactly $ n \tau $. 
	Hardness of \textit{search} XLPN follows directly from standard LPN.
	For search XLPN, it is important that the adversary only gets a single sample.
	If given polynomial many samples, the search to decision reduction can be shown, but then the it is not known if the ``many samples'' search XLPN is equivalent to standard LPN.
	\textcolor{red}{It is open whether decisional XLPN is equivalent to LPN or not.}
	
	\item \cite{JC:KatShiSmi10} have suggested a version of LPN where Hamming weight is restricted to be at most $\lceil q\tau \rfloor$ as a way to have more efficient LPN based cryptosystem instantiations.
	\textcolor{red}{Any follow-up/results from this?}
	
	\item \textbf{Ring-LPN \cite{HKLPP12}.} 
	
\end{enumerate} 

\noindent Constructions, results, and open problems from LPN. 
\begin{enumerate}
	\item LPN -> OWFs
	\paragraph{Construction.} Fix $A\getsr \bbZ_2^{n\times \ell}$.
	For a function $f$ on input $x$ such that $x$ is sufficiently long, use $x$ to sample $\bs \drawn U_r$ and $\be \drawn \pred{Ber}_\tau^n$.
	If $\pred{wt}(e) \geq n\cdot \frac{1/2+\tau}{2}$, output $\bot$ (by Chernoff this happens with exponentially small probability).
	Else, output $(A, A\cdot\bs\oplus\be)$.
	Any algorithm which finds a preimage must find the unique $\bs$, which would contradict the LPN hardness assumption.
	So $f$ is one-way.
	\begin{itemize}
		\item This implies standard corollaries of OWFs, like PRGs, PRFs, or PRPs.
		\textcolor{red}{It is open if the construction of these primitives in this manner (LPN -> OWF -> PRP, for example) can compete with dedicated constructions in efficiency.}
	\end{itemize}

	\item LPN -> PRGs
	\paragraph{Construction.} By the equivalence of search and decisional LPN, by definition a sample from the decisional LPN problem is already pseudorandom.
	Therefore it is an efficient and simple PRG \cite{C:BFKL93}.
	Use an input $\br$ to sample $A, \bs, \be$ and output $(A,A\cdot\bs\oplus \be)$.
	\cite{C:ACPS09} make the observation that $A$ can be fixed as a public parameter, so it need not be sampled or included in the output.
	This reduces the overall randomness complexity.
	
	For any $\tau < 1/2$, $\ell \in \bbZ$, and sufficiently large $n$, we can indeed construct this PRG using seed $\br$ where $\mathrm{len}(\br) = r < n$.
	We need $\ell$ bits to sample $\bs \drawn U_\ell$.
	Further, each bit of $\be \drawn \pred{Ber}_\tau^n$ only has $h_2(\tau)$ bits of entropy.
	Efficient sampling using roughly this many bits is possible \cite{C:ACPS09}.
	So $(\bs, \be)$ has $\ell + nh_2(\tau)$ bits of entropy.
	For sufficiently large $n$, we indeed have $r = \ell + nh_2(\tau) < n$.
	This gives a PRG with stretch $(1 - h_2(\tau))n-\ell$, which is linear in the length $\ell + nh_2(\tau)$ of the seed.
	
	\cite{C:ACPS09} also suggest a variant using several (say $k$) $\ell$-bit keys arranged as a matrix $S \getsr \bbZ^{\ell \times k}_2$.
	For a right choice of $n = \poly(\ell)$, fast matrix multiplication \cite{Coppersmith82} to compute $A\cdot S \oplus E$, where $E \drawn \pred{Ber}_\tau^{n\times k}$, which gives a PRG which can be evaluated in time $\widetilde{O}(nk)$.
	This is asymptotic and it is not clear if this useful in practice, as $n$ and $k$ must be on the order of $\ell^6$, so the seed has size on the order $\ell^{12}$.
	
	\item LPN -> secret-key encryption \cite{ICALP:GilRobSeu08}.
	\paragraph{Construction.} The encryption scheme using LPN given by \cite{ICALP:GilRobSeu08} is as follows.
	For a message $\bm$ with secret key $\bs \drawn U_\ell$, we encrypt $\bm$ as $(A, A\cdot\bs \oplus \be \oplus G\cdot \bm)$.
	Here, $G \in \bbZ_2^{n\times \ell}$ is the generator matrix of a linear code such that the code $C$ generated by $G$ can correct $\tau'\cdot n$ errors, for some $\tau' > \tau$.
	Decryption of ciphertext $(A, \by)$ is done by computing $y \oplus A\cdot\bs = G\cdot \bm \oplus \be$.
	Since $G\cdot \bm \oplus \be$ is a noisy codeword with $\tau \cdot n$ errors (with high probability), we can perform error recovery and recover $G\cdot \bm$ (assuming $\pred{wt}(\be) \leq \tau'\cdot n$).
	The scheme is secure under chosen message attacks, which follows from the decisional LPN assumption.
	
	Further, since subspace LPN and LPN are equivalent, the scheme is secure against {\em related key attacks}, where the adversary also is given encryptions under they key $\phi(s)$, where $\phi$ is any adaptively chosen affine function such that the linear part has sufficiently high rank $\ell' \leq \ell$ such that LPN is hard for $\ell'$.
	\cite{C:ACPS09} show a minor variant of the scheme is secure under a large class of key-dependent message attacks.
	
	\item LPN -> Secret-Key Identification and Message Authentication.
	
	\item LPN -> Public-Key Identification, String Commitments, and Zero-Knowledge.
	
	\item XLPN -> UC-OT protocol with active static security \cite{BerDowNas14}.
	\paragraph{Result.} 
	Using the (decisional) XLPN assumption (that is, the noise vector has weight exactly $\lceil \tau n\rfloor$), the construct a UC OT protocol that is secure against active static adversaries.
	The protocol is built within the CRS model.
	Authors note this is a feasibility result, and lacks efficiency (has high round and communication complexity).
	\textcolor{red}{Is there an efficient construction using this assumption?
	Using search XLPN (this would imply standard LPN gives the same result since search LPN -> search XLPN)?}
	
	\item LPN -> PKE \cite{C:YuZha16,HanLiu17}.
	\paragraph{Result of \cite{C:YuZha16}.}
	This result proves that the LPN problem with constant noise and axillary input is hard.
	This result allows them to construct both CPA and CCA secure public key encryption schemes from constant noise LPN.
	
	The result also gives a variant of the LPN problem called \textit{LPN on squared-log entropy}.
	That is, the secret $\bs$ need not be uniform, but have some squared-logarithmic entropy (\ie, $\minentropy[\bs] \geq \Theta(\log^2 n)$), and the matrix $A$ is sampled from a random subspace of sublinear dimension.
	This answers one part of the LPN problem from min-entropy secrets; others remain for general min-entropy (\ie $\minentropy[\bs]\geq k$ for some $k$).
	
	\paragraph{Result of \cite{HanLiu17}.}
	This result gives the first KDM-secure public key encryption scheme for affine functions from constant noise LPN, for $\ell$ predefined users.
	It enjoys (roughly) the same efficiency of the scheme of \cite{C:YuZha16} (cf. \cite[Table 1]{HanLiu17}).
	Using the LPN on squared-log entropy as a starting point, they construct two ``multi-fold versions'' of the LPN on squared-log entropy, one with \textit{independent secrets}, and the other with \textit{independent subspaces}.
	That is, the samples $(\ba_i, \ip{\ba_i}{\bs_i}+\be_i)$ are computationally indistinguishable from uniform, and either all $s_i$ are independent or all $a_i$.
	They establish hardness on these variants on constant noise LPN.
	
	\item LPN -> PRF \cite{EC:YuSte16}.
	This result gives a construction of efficient and parallelizable randomized PRFs from LPN.
	The LPN instantiation uses noise rate $1/n^c$ for any constant $0 < c < 1$,
	and the PRFs can be implemented with a family of poly-size circuits with unbounded fan-in AND, OR, and XOR gates with $\omega(1)$ depth, for any small super-constant (\eg, $\log\log\log n$).
	
	The construction of the PRFs has a tradeoff between the following when an adversary can make up to a certain super-poly amount of queries.
	\begin{itemize}
		\item PRF on weak key of sublinear entropy (or uniform key with $(1-o(1))$-fraction leakage) has comparable security to underlying LPN on linear secret size.
		\item PRF with key lengith $\lambda$ can have security up to $2^{O(\lambda/\log \lambda)}$, which is beyond the security of the underlying low-noise LPN.
	\end{itemize}
	
	The result is stated as follows.
	\TODO{TODO: Try and put theorem in English.}
	\begin{importedtheorem}[{\cite[Theorem 1.1]{EC:YuSte16}}]
		Assume that the LPN problem with secret length $n$ and noise rate $\mu = n^{-c}$ (for any constant $0 < c < 1$) is ($ q=1.001n, t=2^{O(n^{1-c})} $)-hard.
		Then,
		\begin{enumerate}
			\item for any $d = \omega(1)$, there exists a $(q'=n^{d/3}, t-q'\poly(n), O(nq'\eps))$-randomized-PRF on any weak key of R\'enyi entropy no less than $O(n^{1-c}\cdot \log n)$, or on an $n^{1-c/2}$-bit uniform random key with any $(1 - O(\log n)/n^{c/2})$-fraction of leakage (independent of the public coins of the PRF);
			\item let $\lambda = \Theta(n^{1-c}\log n)$, for any $d = \omega(1)$, there exists a $(q' = \lambda^{\Theta(d)}, t' = 2^{O(\lambda / \log \lambda)}, \eps' = 2^{-O(\lambda/ \log \lambda)})$-randomized PRF with key length $\lambda$;
		\end{enumerate}
	where both PRFs are computable by polynomial-size depth $O(d)$ circuits with unbounded fan-in AND, OR, and XOR gates.
	\end{importedtheorem}
	
	\textcolor{red}{Constant depth construction? 
	Constant noise LPN construction?}
	
	\item \textcolor{red}{LPN -> CRHF}
	
	\item \textcolor{red}{LPN -> FHE}
	
	\item \textcolor{red}{Does LPN for a given $\tau$ imply LPN is hard for any $\tau' < \tau$?
	Is there a threshold such that LPN is hard for $\tau$ but easy for any $\tau' < \tau$?}
\end{enumerate}